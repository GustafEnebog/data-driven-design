{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Evaluate missing data\n",
        "*   Clean data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/airplane_performance_study.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate cleaned Train and Test sets, both saved under outputs/datasets/cleaned\n",
        "\n",
        "## Conclusions\n",
        "\n",
        " \n",
        "  * Data Cleaning Pipeline\n",
        "  * Drop Variables:  `['Model', 'Company', 'THR', 'SHP']`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kspgyffxear-"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* Access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Collected data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2ELZj83tF1g",
        "outputId": "d51e2567-7f6c-4200-b9c2-d4982d22e6fd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_raw_path = \"/workspace/data-driven-design/outputs/datasets/collection/airplane_performance_study.csv\"\n",
        "df = pd.read_csv(df_raw_path)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning - Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset is already cleaned thus we should be able to expect no missing data however `['THR', 'SHP']` do have apparent missing data in its columns. The reason for this is that \"size\" of an engine is measured with different quantities/units depending on ` Engine Type`. The jet is measured in quantity of force (unit: THR) and the piston and propjet (both propeller) is measured using power (unit: SHP). For this reason these units are split into two separate columns and a jet data point will then have N/A in the SHP column and a prop or propjet (turbo prop) will have a N/A in the THR column. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                   \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                   \"DataType\": df.dtypes}\n",
        "                                    )\n",
        "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                          .query(\"PercentageOfDataset > 0\")\n",
        "                          )\n",
        "\n",
        "    return df_missing_data\n",
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Features to drop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will drop the following features:\n",
        "* `'THR'` and `'THR'` since these are different quantities with different untis and therefore difficult to compare with each other.\n",
        "* `'Model'` and `'Company'` since this meta data only serve as identifier variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We drop values in this stage already since subsequents code otherwise would fail. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List here the data cleaning approaches you want initially to try.\n",
        "* Drop - `['Model', 'Company', 'THR', 'SHP']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Columns to drop\n",
        "columns_to_drop = ['Model', 'Company', 'THR', 'SHP']\n",
        "\n",
        "# Dropping the columns\n",
        "df_dropped = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Overwriting to the droped data frame\n",
        "df =  df_dropped\n",
        "\n",
        "# Display the modified DataFrame\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvwabO0JsmYW"
      },
      "source": [
        "## Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install ppscore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "g6Zy_MglsmYo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\")\n",
        "    df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryNo1VnXSK9K"
      },
      "source": [
        "Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In below cell I have to drop values to make the correlation below to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Z4SXf6GbED",
        "outputId": "6978dbde-ebb0-4023-af6c-b6f896ced798"
      },
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df_dropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ-0L4PiSPEK"
      },
      "source": [
        "Display at Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(df_dropped)\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solve issue with \"AttributeError: model 'numpy' has no attribute 'bool'. 'np.bool' was a deprecated alias for the builtin 'bool'...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.bool = np.bool_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solve issue that the plots were not being displayed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have added the Predictive Power Score (PPS) since PPS also can detect non-linear relationships that the traditional metrics like Pearson or Spearman correlations might miss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations and conclusion from below heatmaps:\n",
        "\n",
        "* We naturally see high correlation between features of the same kind, e.g. we see high correlation (0,85 - 0,88) between the \"weight\"-features like \"All Up Weight\" (AUW), Fuel Weight(FW) and \"Manufacturer Empty Weight\" (MEW) since both are \"weight\"-features. We also see high correlation between features in related kinds, e.g. the size of the airplane (Height, Length and Wing Span) are obvioously strongly related to airplanes weight (AUW, FW and MEW).\n",
        "\n",
        "* Albeit not really interresting from an Airplane Design perspective these relationships can still be used to predict values. Note tha the relatinship between size and weight (due to structural and aerodynamic scale factors) might not be linear. \n",
        "\n",
        "* Interesting correlations are between: 0.8 - 1.0:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running heatmaps with low threshold to allowe both **weakly**, **moderate** and **strongly** correlated features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ioE3yuC4Q7QK",
        "outputId": "1946ffa1-2e5d-4972-eeda-45d7fe382314"
      },
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.3, PPS_Threshold =0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we run the correlation again with elevated thresholds as to only filter out both weakly and moderate correlation values leaving only **strongly** correlated features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.7, PPS_Threshold =0.5,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYdZHyDhu4kG"
      },
      "source": [
        "# Data Cleaning - Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxoVRefhu2Bk"
      },
      "source": [
        "## Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt8Yqjy6ghyw"
      },
      "source": [
        "### Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4GaYe_DgqwT"
      },
      "source": [
        "The following data cleaning actions have been taken:\n",
        "* Drop - `['Model', 'Company', 'THR', 'SHP']`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W12Z8KIPoZ-8"
      },
      "source": [
        "### Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knk7DcVborLI",
        "outputId": "049ef5f2-c431-4a9d-fd87-00809986c38d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['Multi_Engine'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "zdMPKBU_yCpF",
        "outputId": "df45adaf-5e93-4644-919f-6b82e51fe8b7"
      },
      "outputs": [],
      "source": [
        "df_missing_data = EvaluateMissingData(TrainSet)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD--GI5Jvp8h"
      },
      "source": [
        "# Push cleaned data to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE3DQfy82r7I"
      },
      "source": [
        "## Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Q1ayKT4F2p52"
      },
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTTabVk-2ulD"
      },
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zCjorYny2qCD"
      },
      "outputs": [],
      "source": [
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
